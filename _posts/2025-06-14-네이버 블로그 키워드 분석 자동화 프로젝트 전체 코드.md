---

title: "[python] ë„¤ì´ë²„ ë¸”ë¡œê·¸ í‚¤ì›Œë“œ ë¶„ì„ ìë™í™” í”„ë¡œì íŠ¸ ì „ì²´ ì½”ë“œ"
date: 2025-06-14 04:07:00 +0900
categories: [data-analysis, naver, sns, keyword]
tags: [ë„¤ì´ë²„, í¬ë¡¤ë§, ì›Œë“œí´ë¼ìš°ë“œ, python, ìë™í™”, ì¸ì‚¬ì´íŠ¸,sentiment-analysis, ë°ì´í„°ë§ˆì¼€íŒ…, ìë™í™”ë¶„ì„, ë°ì´í„°ë¦¬ì„œì¹˜]
pin: true

---

# ğŸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ëŸ¬

## [colab í™˜ê²½] í¬ë¡¬ë“œë¼ì´ë²„, í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì…‹ì—… 
```
!apt-get update
!apt install -y chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin/
!pip install selenium beautifulsoup4 pandas
!pip install chromedriver-autoinstaller

import chromedriver_autoinstaller
chromedriver_autoinstaller.install()

import requests
import json
import urllib.parse
import re
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
import pandas as pd
from datetime import datetime
import pytz
from google.colab import files
```

## 1. ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ url/ì œëª©/ë‚ ì§œ ìˆ˜ì§‘ (OpenAPI ì‚¬ìš©)
```
def naver_blog_search(client_id, client_secret, keyword, end=1, display=10, sleep_sec=1.0):
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    encText = urllib.parse.quote(keyword)
    urls, dates, titles = [], [], []
    for page in range(end):
        start = page * display + 1
        url = f"https://openapi.naver.com/v1/search/blog?query={encText}&start={start}&display={display}"
        res = requests.get(url, headers=headers)
        if res.status_code == 200:
            data = res.json().get('items', [])
            for row in data:
                link = row.get('link', '')
                if 'blog.naver' in link:
                    urls.append(link)
                    dates.append(row.get('postdate', ''))
                    # ì œëª© ë‚´ HTML íƒœê·¸ ì œê±°
                    title = re.sub('<[^>]*>', '', row.get('title', ''))
                    titles.append(title)
            print(f'í˜ì´ì§€ {page+1} ì™„ë£Œ (ëˆ„ì  {len(urls)}ê±´)')
        else:
            print(f"API Error: {res.status_code}")
        time.sleep(sleep_sec)  # API ê³¼ë¶€í•˜ ë°©ì§€
    return urls, dates, titles
```

## 2. ì…€ë ˆë‹ˆì›€ ì›¹ë“œë¼ì´ë²„ ì„¤ì • (colab/ì„œë²„ í™˜ê²½ì— ë§ê²Œ headless)
```
def get_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1280x1696')
    options.add_argument('--remote-debugging-port=9222')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    chromedriver_path = chromedriver_autoinstaller.install()
    service = Service(chromedriver_path)
    driver = webdriver.Chrome(service=service, options=options)
    driver.implicitly_wait(3)  # ì•”ì‹œì  ëŒ€ê¸° (ë¡œë”© ì•ˆì •í™”)
    return driver
```

## 3. ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ (iframe ìë™ ê°ì§€/ì§„ì…)
```
def extract_content(driver, url, max_wait=5):
    try:
        driver.get(url)
        # mainFrame iframe ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° í›„ ì§„ì…
        for _ in range(max_wait * 2):
            try:
                iframe = driver.find_element(By.ID, "mainFrame")
                driver.switch_to.frame(iframe)
                break
            except:
                time.sleep(0.5)
        html = BeautifulSoup(driver.page_source, "html.parser")
        # ì—ë””í„° ìœ í˜•ë³„ë¡œ ë³¸ë¬¸ div íƒìƒ‰
        main = html.select_one("div.se-main-container") or html.select_one("#postViewArea")
        if main:
            text = main.get_text(separator="\n", strip=True)
            return text.strip()
        return ""
    except Exception as e:
        print(f"[ë³¸ë¬¸ íŒŒì‹± ì—ëŸ¬] {url}: {e}")
        return ""
```

## 4. ì „ì²´ í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ (ê²€ìƒ‰ â†’ ë³¸ë¬¸ í¬ë¡¤ â†’ CSV ì €ì¥/ë‹¤ìš´ë¡œë“œ)
```
def naver_blog_crawler(client_id, client_secret, keyword, end=1, display=10, sleep_sec=1.2, prefix='blog'):
    # íŒŒì¼ëª…: blog_ë‚ ì§œ_ì‹œê°„.csv í˜•íƒœ ìë™ìƒì„± (KST)
    KST = pytz.timezone('Asia/Seoul')
    now = datetime.now(KST).strftime('%Y%m%d_%H%M%S')
    out_csv = f'blog_{now}.csv'

    # 1ë‹¨ê³„: ê²€ìƒ‰ê²°ê³¼ url/ë‚ ì§œ/ì œëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    urls, dates, titles = naver_blog_search(client_id, client_secret, keyword, end, display, sleep_sec)
    driver = get_driver()
    contents = []
    # 2ë‹¨ê³„: ê° ë¸”ë¡œê·¸ urlì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§
    for idx, url in enumerate(urls):
        print(f"{idx+1}/{len(urls)} ë³¸ë¬¸ í¬ë¡¤ë§: {url}")
        contents.append(extract_content(driver, url))
    driver.quit()
    # 3ë‹¨ê³„: DataFrameìœ¼ë¡œ ì €ì¥ í›„ CSVë¡œ ë‚´ë³´ë‚´ê¸°
    df = pd.DataFrame({'title': titles, 'content': contents, 'date': dates})
    df.to_csv(out_csv, index=False, encoding='utf-8-sig')
    print(f"\n{out_csv}ë¡œ ì €ì¥ ì™„ë£Œ! (ì´ {len(df)}ê°œ)")
    files.download(out_csv)  # colab íŒŒì¼ ë‹¤ìš´ë¡œë“œ
```

## 5. ì‹¤í–‰ë¶€: ì‚¬ìš©ì ì…ë ¥ ë°›ì•„ í¬ë¡¤ë§ ì‹œì‘
```
client_id = 'bumtntsqPoT7Gz1aqUhW'
client_secret = 'beSV3TZU3p'
keyword = input("ê²€ìƒ‰í•  í‚¤ì›Œë“œ: ").strip()
end = input("ê°€ì ¸ì˜¬ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ 1): ").strip()
display = input("í•œ í˜ì´ì§€ë‹¹ ê°œìˆ˜ (ê¸°ë³¸ 10): ").strip()
end = int(end) if end.isdigit() else 1
display = int(display) if display.isdigit() else 10
naver_blog_crawler(client_id, client_secret, keyword, end, display, sleep_sec=1.5, prefix='blog')
```
---
# â˜ï¸ csvì „ì²˜ë¦¬ + ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”

## 1. í•œê¸€ ìì—°ì–´/ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ 

```
!pip install konlpy
!apt-get -y install fonts-nanum
```

## 2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
```
from konlpy.tag import Okt
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
import re
import numpy as np
from PIL import Image
import os
```

## + ë‚˜ëˆ”í°íŠ¸ ê²½ë¡œ ì§€ì • (ì›Œë“œí´ë¼ìš°ë“œ í•œê¸€ì¶œë ¥ìš©)
```
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
```
## + ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ë³€í™˜
```
from google.colab import files

def get_mask_image():
    print('ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)')
    if input().strip().lower() == 'y':
        up = files.upload()
        mask_fname = list(up.keys())[0]
        try:
            mask = np.array(Image.open(mask_fname))
            print(f"[INFO] ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì ìš©: {mask_fname}")
            return mask
        except Exception as e:
            print("[ê²½ê³ ] ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨. ê¸°ë³¸ ì‚¬ê°í˜• ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            return None
    else:
        print("[INFO] ê¸°ë³¸(ë„¤ëª¨) ì›Œë“œí´ë¼ìš°ë“œë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        return None

mask = get_mask_image()  # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì ìš©(ì„ íƒì )
```

## 3. ë¶„ì„í•  CSV íŒŒì¼ ì—…ë¡œë“œ
```
print("\në¶„ì„í•  CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
up = files.upload()
filename = list(up.keys())[0]
```

## 4. ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³¸ë¬¸ ì „ì²´ í•©ì¹˜ê¸°
```
df = pd.read_csv(filename)
text = ' '.join(df['content'].astype(str))
```

## 5. íŠ¹ìˆ˜ë¬¸ì/ê¸°í˜¸/ì˜ì–´ ë“± ì œê±° (í•œê¸€, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¹€)
```
text = re.sub(r'[^\w\sã„±-ã…ê°€-í£]', ' ', text)
text = text.replace('\n', ' ')
```

## 6. Okt í˜•íƒœì†Œë¶„ì„ê¸°ë¡œ ëª…ì‚¬ë§Œ ì¶”ì¶œ
```
okt = Okt()
nouns = okt.nouns(text)
print("ëª…ì‚¬ ìƒ˜í”Œ:", nouns[:20])
```

## 7. ë¶ˆìš©ì–´ ì œê±°

```
stopwords = set([
    'ê²ƒ','ë”','ë˜','ì—ì„œ','í•˜ëŠ”','í•˜ë©´','í•˜ê³ ','ìš”','ì','ë¡œ','ì™€','ê³¼','ë„','ì„','ë¥¼','ì€','ëŠ”','ì´','ê°€','ì—','ì˜','í•œ','ë°','ê³ ','ë‚˜','ë³´ë‹¤','ë°–ì—','ì²˜ëŸ¼','ë¶€í„°',
    'ë‚´ê°€','ë‚´','ë„ˆë¬´','ì •ë§','ë§¤ìš°','ì§„ì§œ','ê°™ì•„ìš”','ã…ã…','ì €ëŠ”','ìˆëŠ”','ìˆì–´ì„œ','ìˆëŠ”','ìˆê³ ','ìˆë‹¤'
])
words = [w for w in nouns if w not in stopwords and len(w) > 1]
```

## 8. ë‹¨ì–´ë³„ ë“±ì¥ ë¹ˆë„ ê³„ì‚°
```
word_count = Counter(words)
```

## 9. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì„ íƒ)
```
wc = WordCloud(
    font_path=font_path, 
    background_color='white',
    width=800, height=800,
    mask=mask   # Noneì´ë©´ ë„¤ëª¨, ì„ íƒ ê°€ëŠ¥
)
wc_img = wc.generate_from_frequencies(word_count)
```

## 10. ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”
```
plt.figure(figsize=(10, 10))
plt.imshow(wc_img, interpolation='bilinear')
plt.axis('off')
plt.show()
```

## 11. ë“±ì¥ ë¹ˆë„ Top 30 ëª…ì‚¬ ì¶œë ¥
```
print('\nìƒìœ„ 30ê°œ ëª…ì‚¬:')
for word, count in word_count.most_common(30):
    print(f"{word}: {count}")
```
